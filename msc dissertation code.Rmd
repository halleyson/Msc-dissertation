---
title: "msc dissertation"
author: "Halleyson Li"
date: "'r Sys.Date()'"
output: html_document
line-citations: apalike
linkcolor: blue
frontsize: 12pt
---

\newpage

# *Notes*{-}
1. The GitHub repository for this project could access through [here](https://github.com/halleyson/msc-dissertation.git)

# Loading data

```{r, message=FALSE}

library(readr)

pennycook2 <- read_csv("Pennycook et al._Study 2.csv")
# Quick check
head(pennycook2)

```

# General steps to regenerate headline result (study 2)
## data cleaning

```{r, message=FALSE}

# rename columns that contains special characters
colnames(pennycook2)
names(pennycook2)[1] <- "condition"


#remove a participants that did not answer or fail to record any questions

pennycook2 <- pennycook2[!is.na(pennycook2$Fake),]


#data description: condition 1 = control; condition 2 = treatment 

#Choose with the column position 
library("dplyr")
pennystudy2r1 <- pennycook2 %>% 
  select (c(1, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 2, 3, 4, 57, 60, 250, 252, 284,))

#re-code sharing intentions (fake/real) using the scale midpoint (1-3 = 0, 4-6 = 1)

##Fake
pennystudy2r1$Fake[pennystudy2r1$Fake > 0 & pennystudy2r1$Fake < 4] <- 0
pennystudy2r1$Fake[pennystudy2r1$Fake > 3 & pennystudy2r1$Fake < 7] <- 1
pennystudy2r1$Fake

pennystudy2r1$Fake1_1[pennystudy2r1$Fake1_1 > 0 & pennystudy2r1$Fake1_1 < 4] <- 0
pennystudy2r1$Fake1_1[pennystudy2r1$Fake1_1 > 3 & pennystudy2r1$Fake1_1 < 7] <- 1

pennystudy2r1$Fake1_2[pennystudy2r1$Fake1_2 > 0 & pennystudy2r1$Fake1_2 < 4] <- 0
pennystudy2r1$Fake1_2[pennystudy2r1$Fake1_2 > 3 & pennystudy2r1$Fake1_2 < 7] <- 1

pennystudy2r1$Fake1_3[pennystudy2r1$Fake1_3 > 0 & pennystudy2r1$Fake1_3 < 4] <- 0
pennystudy2r1$Fake1_3[pennystudy2r1$Fake1_3 > 3 & pennystudy2r1$Fake1_3 < 7] <- 1

pennystudy2r1$Fake1_4[pennystudy2r1$Fake1_4 > 0 & pennystudy2r1$Fake1_4 < 4] <- 0
pennystudy2r1$Fake1_4[pennystudy2r1$Fake1_4 > 3 & pennystudy2r1$Fake1_4 < 7] <- 1

pennystudy2r1$Fake1_5[pennystudy2r1$Fake1_5 > 0 & pennystudy2r1$Fake1_5 < 4] <- 0
pennystudy2r1$Fake1_5[pennystudy2r1$Fake1_5 > 3 & pennystudy2r1$Fake1_5 < 7] <- 1

pennystudy2r1$Fake1_6[pennystudy2r1$Fake1_6 > 0 & pennystudy2r1$Fake1_6 < 4] <- 0
pennystudy2r1$Fake1_6[pennystudy2r1$Fake1_6 > 3 & pennystudy2r1$Fake1_6 < 7] <- 1

pennystudy2r1$Fake1_7[pennystudy2r1$Fake1_7 > 0 & pennystudy2r1$Fake1_7 < 4] <- 0
pennystudy2r1$Fake1_7[pennystudy2r1$Fake1_7 > 3 & pennystudy2r1$Fake1_7 < 7] <- 1

pennystudy2r1$Fake1_8[pennystudy2r1$Fake1_8 > 0 & pennystudy2r1$Fake1_8 < 4] <- 0
pennystudy2r1$Fake1_8[pennystudy2r1$Fake1_8 > 3 & pennystudy2r1$Fake1_8 < 7] <- 1

pennystudy2r1$Fake1_9[pennystudy2r1$Fake1_9 > 0 & pennystudy2r1$Fake1_9 < 4] <- 0
pennystudy2r1$Fake1_9[pennystudy2r1$Fake1_9 > 3 & pennystudy2r1$Fake1_9 < 7] <- 1

pennystudy2r1$Fake1_10[pennystudy2r1$Fake1_10 > 0 & pennystudy2r1$Fake1_10 < 4] <- 0
pennystudy2r1$Fake1_10[pennystudy2r1$Fake1_10 > 3 & pennystudy2r1$Fake1_10 < 7] <- 1

pennystudy2r1$Fake1_11[pennystudy2r1$Fake1_11 > 0 & pennystudy2r1$Fake1_11 < 4] <- 0
pennystudy2r1$Fake1_11[pennystudy2r1$Fake1_11 > 3 & pennystudy2r1$Fake1_11 < 7] <- 1

pennystudy2r1$Fake1_12[pennystudy2r1$Fake1_12 > 0 & pennystudy2r1$Fake1_12 < 4] <- 0
pennystudy2r1$Fake1_12[pennystudy2r1$Fake1_12 > 3 & pennystudy2r1$Fake1_12 < 7] <- 1

pennystudy2r1$Fake1_13[pennystudy2r1$Fake1_13 > 0 & pennystudy2r1$Fake1_13 < 4] <- 0
pennystudy2r1$Fake1_13[pennystudy2r1$Fake1_13 > 3 & pennystudy2r1$Fake1_13 < 7] <- 1

pennystudy2r1$Fake1_14[pennystudy2r1$Fake1_14 > 0 & pennystudy2r1$Fake1_14 < 4] <- 0
pennystudy2r1$Fake1_14[pennystudy2r1$Fake1_14 > 3 & pennystudy2r1$Fake1_14 < 7] <- 1

pennystudy2r1$Fake1_15[pennystudy2r1$Fake1_15 > 0 & pennystudy2r1$Fake1_15 < 4] <- 0
pennystudy2r1$Fake1_15[pennystudy2r1$Fake1_15 > 3 & pennystudy2r1$Fake1_15 < 7] <- 1


##Real
pennystudy2r1$Real[pennystudy2r1$Real > 0 & pennystudy2r1$Real < 4] <- 0
pennystudy2r1$Real[pennystudy2r1$Real > 3 & pennystudy2r1$Real < 7] <- 1
pennystudy2r1$Real

pennystudy2r1$Real1_1[pennystudy2r1$Real1_1 > 0 & pennystudy2r1$Real1_1 < 4] <- 0
pennystudy2r1$Real1_1[pennystudy2r1$Real1_1 > 3 & pennystudy2r1$Real1_1 < 7] <- 1

pennystudy2r1$Real1_2[pennystudy2r1$Real1_2 > 0 & pennystudy2r1$Real1_2 < 4] <- 0
pennystudy2r1$Real1_2[pennystudy2r1$Real1_2 > 3 & pennystudy2r1$Real1_2 < 7] <- 1

pennystudy2r1$Real1_3[pennystudy2r1$Real1_3 > 0 & pennystudy2r1$Real1_3 < 4] <- 0
pennystudy2r1$Real1_3[pennystudy2r1$Real1_3 > 3 & pennystudy2r1$Real1_3 < 7] <- 1

pennystudy2r1$Real1_4[pennystudy2r1$Real1_4 > 0 & pennystudy2r1$Real1_4 < 4] <- 0
pennystudy2r1$Real1_4[pennystudy2r1$Real1_4 > 3 & pennystudy2r1$Real1_4 < 7] <- 1

pennystudy2r1$Real1_5[pennystudy2r1$Real1_5 > 0 & pennystudy2r1$Real1_5 < 4] <- 0
pennystudy2r1$Real1_5[pennystudy2r1$Real1_5 > 3 & pennystudy2r1$Real1_5 < 7] <- 1

pennystudy2r1$Real1_6[pennystudy2r1$Real1_6 > 0 & pennystudy2r1$Real1_6 < 4] <- 0
pennystudy2r1$Real1_6[pennystudy2r1$Real1_6 > 3 & pennystudy2r1$Real1_6 < 7] <- 1

pennystudy2r1$Real1_7[pennystudy2r1$Real1_7 > 0 & pennystudy2r1$Real1_7 < 4] <- 0
pennystudy2r1$Real1_7[pennystudy2r1$Real1_7 > 3 & pennystudy2r1$Real1_7 < 7] <- 1

pennystudy2r1$Real1_8[pennystudy2r1$Real1_8 > 0 & pennystudy2r1$Real1_8 < 4] <- 0
pennystudy2r1$Real1_8[pennystudy2r1$Real1_8 > 3 & pennystudy2r1$Real1_8 < 7] <- 1

pennystudy2r1$Real1_9[pennystudy2r1$Real1_9 > 0 & pennystudy2r1$Real1_9 < 4] <- 0
pennystudy2r1$Real1_9[pennystudy2r1$Real1_9 > 3 & pennystudy2r1$Real1_9 < 7] <- 1

pennystudy2r1$Real1_10[pennystudy2r1$Real1_10 > 0 & pennystudy2r1$Real1_10 < 4] <- 0
pennystudy2r1$Real1_10[pennystudy2r1$Real1_10 > 3 & pennystudy2r1$Real1_10 < 7] <- 1

pennystudy2r1$Real1_11[pennystudy2r1$Real1_11 > 0 & pennystudy2r1$Real1_11 < 4] <- 0
pennystudy2r1$Real1_11[pennystudy2r1$Real1_11 > 3 & pennystudy2r1$Real1_11 < 7] <- 1

pennystudy2r1$Real1_12[pennystudy2r1$Real1_12 > 0 & pennystudy2r1$Real1_12 < 4] <- 0
pennystudy2r1$Real1_12[pennystudy2r1$Real1_12 > 3 & pennystudy2r1$Real1_12 < 7] <- 1

pennystudy2r1$Real1_13[pennystudy2r1$Real1_13 > 0 & pennystudy2r1$Real1_13 < 4] <- 0
pennystudy2r1$Real1_13[pennystudy2r1$Real1_13 > 3 & pennystudy2r1$Real1_13 < 7] <- 1

pennystudy2r1$Real1_14[pennystudy2r1$Real1_14 > 0 & pennystudy2r1$Real1_14 < 4] <- 0
pennystudy2r1$Real1_14[pennystudy2r1$Real1_14 > 3 & pennystudy2r1$Real1_14 < 7] <- 1

pennystudy2r1$Real1_15[pennystudy2r1$Real1_15 > 0 & pennystudy2r1$Real1_15 < 4] <- 0
pennystudy2r1$Real1_15[pennystudy2r1$Real1_15 > 3 & pennystudy2r1$Real1_15 < 7] <- 1

#create veracity column (Real - Fake)
pennystudy2r1['veracity']=pennystudy2r1['Real'] - pennystudy2r1['Fake']

#successful screen1 test (result = 2)
pennystudy2r1['screen1']=pennystudy2r1['screen1_4'] + pennystudy2r1['screen1_7']

#successful screen2 test (result = 2)
pennystudy2r1['screen2']=pennystudy2r1['screen2_3'] + pennystudy2r1['screen2_5']

#successful screen3 test (result = 3)
pennystudy2r1['screen3'] = na_if(pennystudy2r1$screen3_2,1)
pennystudy2r1['screen3'] = na_if(pennystudy2r1$screen3,2)
pennystudy2r1['screen3'] = na_if(pennystudy2r1$screen3,4)
pennystudy2r1['screen3'] = na_if(pennystudy2r1$screen3,5)
#check if screen 3 successful
mean(pennystudy2r1$screen3, na.rm = TRUE)

#re-code screen test: replace 2 and 3 to 1
pennystudy2r1["screen1"][pennystudy2r1["screen1"] == 2] <- 1
pennystudy2r1["screen2"][pennystudy2r1["screen2"] == 2] <- 1
pennystudy2r1["screen3"][pennystudy2r1["screen3"] == 3] <- 1

#re-code condition control = 0 treatment = 1
pennystudy2r1["condition"][pennystudy2r1["condition"] == 1] <- 0
pennystudy2r1["condition"][pennystudy2r1["condition"] == 2] <- 1

#replace NA to 0 in screen 1,2,3

pennystudy2r1[c("screen1","screen2","screen3")][is.na(pennystudy2r1[c("screen1","screen2","screen3")])] <- 0

#create dummy column, add screen 1,2,3 together. Screen = 3 indicate success in all attention check
pennystudy2r1['dummycheck']=pennystudy2r1['screen1'] + pennystudy2r1['screen2'] + pennystudy2r1['screen3']


#like the researcher did, change data frame from wide to long
##first drop unnecessary column
colnames(pennystudy2r1)

pennys2r1long <- subset(pennystudy2r1, select = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,40,44))

##Add ID column
pennys2r1long <- tibble::rowid_to_column(pennys2r1long, "ID")

## change from wide to long
library(tidyr)

keycol <- "newstype"
valuecol <- "measurement"
gathercols <- c("Fake1_1","Fake1_2","Fake1_3","Fake1_4","Fake1_5","Fake1_6","Fake1_7","Fake1_8","Fake1_9","Fake1_10","Fake1_11","Fake1_12","Fake1_13","Fake1_14","Fake1_15","Real1_1","Real1_2","Real1_3","Real1_4","Real1_5","Real1_6","Real1_7","Real1_8","Real1_9","Real1_10","Real1_11","Real1_12","Real1_13","Real1_14","Real1_15")

pennys2r1long <- gather_(pennys2r1long, keycol, valuecol, gathercols)

##no idea why it doesn't show groups (control vs treatment) so I merge original condition to the new one

merge(pennystudy2r1, pennys2r1long, by.x='condition', by.y='ID')

##organize data by ID, then reorder the column
pennys2r1long <- pennys2r1long[order(pennys2r1long$ID),]

pennys2r1long <- pennys2r1long[, c(1, 2, 8, 9, 7, 4, 3, 6, 5)]

##rename real and fake to avereal and avefake, change dummycheck to attentioncheck to make it clear

names(pennys2r1long)[6] <- "Real_ave"
names(pennys2r1long)[7] <- "Fake_ave"
names(pennys2r1long)[5] <- "attentioncheck"

##create a headline veracity column, fake news items code as 0, real news items code as 1

pennys2r1long <- pennys2r1long %>%
  mutate(headlineveracity = case_when(
    startsWith(newstype, "R") ~ "1",
    startsWith(newstype, "F") ~ "0"
    ))

##realise that original researcher exclude the observation with answer contains na, thus the obs needs to minus 23 to match original obs 25,627

pennys2r1long_nona <- pennys2r1long[!is.na(pennys2r1long$measurement),]

##separating the data based on number of successful attention check

### attention check above and equal to 1
pennys2r1longa1 <- subset(pennys2r1long, attentioncheck %in% c("1","2","3"))

### attention check above and equal to 2
pennys2r1longa2 <- subset(pennys2r1long, attentioncheck %in% c("2","3"))

### attention check equal to 3
pennys2r1longa3 <- subset(pennys2r1long, attentioncheck %in% c("3"))


###find out the number of participants (obs) for each attention check level
attention1 <- subset(pennystudy2r1, dummycheck %in% c("1","2","3"))
attention2 <- subset(pennystudy2r1, dummycheck %in% c("2","3"))
attention3 <- subset(pennystudy2r1, dummycheck %in% c("3"))
```


## reproduction of results (interaction between headline veracity and treatment)
### without considering attention check
```{r, message=FALSE}
install.packages("sandwich") 
install.packages("stargazer")
install.packages("lmtest")
library(lmtest)
library(stargazer) 
library(sandwich)


lm1 <- lm(measurement ~ headlineveracity + headlineveracity*condition, data = pennys2r1long_nona)
summary(lm1)

stargazer(lm1, type='text')

coeftest(lm1, vcovHC)

#z scored
scale(pennystudy2r1$Discern)

#calculate the effect size cohen's d
##since they need to compare true vs false headline in different condition, thus, create a new data frame that only contain treatment and control with the attention check above and equal to 2, as stated in the research

install.packages("effsize")
library(effsize)

pennys2r1a2cohen <- subset(pennystudy2r1, dummycheck %in% c("2","3"))
pennys2r1a2cohenc <- subset(pennys2r1a2cohen, condition %in% c("0"))
pennys2r1a2cohent <- subset(pennys2r1a2cohen, condition %in% c("1"))




cohen.d(pennys2r1a2cohenc$Fake, pennys2r1a2cohenc$Real, na.rm = TRUE)
cohen.d(pennys2r1a2cohent$Fake, pennys2r1a2cohent$Real, na.rm = TRUE)


#condition vs measurement

pennys2r1a2cohenc <- subset(pennys2r1longa2, condition %in% c("0"))
pennys2r1a2cohent <- subset(pennys2r1longa2, condition %in% c("1"))




cohen.d(pennys2r1a2cohenc$condition, pennys2r1a2cohenc$measurement, na.rm = TRUE)
cohen.d(pennys2r1a2cohent$condition, pennys2r1a2cohent$measurement, na.rm = TRUE)

```



##Try something new, see if it makes the results better
```{r, message=FALSE}
## use glm, stepwise approach to see how each factor explaining the sharing intention. The family for the model is binomial since the dependent variable is dichotomous.
glm0 <- glm(measurement ~ 1, data = pennys2r1long_nona, family = binomial(link = "logit"))

glm1 <- glm(measurement ~ condition, data = pennys2r1long_nona, family = binomial(link = "logit"))

glm2 <- glm(measurement ~ condition + attentioncheck, data = pennys2r1long_nona, family = binomial(link = "logit"))

glm3 <- glm(measurement ~ condition + attentioncheck + headlineveracity, data = pennys2r1long_nona, family = binomial(link = "logit"))

glm4 <- glm(measurement ~ condition + attentioncheck +condition* headlineveracity, data = pennys2r1long_nona, family = binomial(link = "logit"))


anova(glm0,glm1,glm2,glm3,glm4,test='LR')

##looking at summary glm4, it is cleat that condition does not have a significant effect on measurement
summary(glm6)

glm5 <- glm(measurement ~ attentioncheck +condition* headlineveracity, data = pennys2r1long_nona, family = binomial(link = "logit"))
glm6 <- glm(measurement ~ headlineveracity + attentioncheck +condition* headlineveracity, data = pennys2r1long_nona, family = binomial(link = "logit"))

summary(glm7)


##maybe a mixed effect models?
#create a new column that recode item number from fake to real to 1-30, with 1-15 indicate fake, 16-30 indicate real

pennys2r1long <- within(pennys2r1long,{
  item_id <- NA
  item_id[newstype == "Fake1_1"] <- 1
  item_id[newstype == "Fake1_2"] <- 2
  item_id[newstype == "Fake1_3"] <- 3
  item_id[newstype == "Fake1_4"] <- 4
  item_id[newstype == "Fake1_5"] <- 5
  item_id[newstype == "Fake1_6"] <- 6
  item_id[newstype == "Fake1_7"] <- 7
  item_id[newstype == "Fake1_8"] <- 8
  item_id[newstype == "Fake1_9"] <- 9
  item_id[newstype == "Fake1_10"] <- 10
  item_id[newstype == "Fake1_11"] <- 11
  item_id[newstype == "Fake1_12"] <- 12
  item_id[newstype == "Fake1_13"] <- 13
  item_id[newstype == "Fake1_14"] <- 14
  item_id[newstype == "Fake1_15"] <- 15
  item_id[newstype == "Real1_1"] <- 16
  item_id[newstype == "Real1_2"] <- 17
  item_id[newstype == "Real1_3"] <- 18
  item_id[newstype == "Real1_4"] <- 19
  item_id[newstype == "Real1_5"] <- 20
  item_id[newstype == "Real1_6"] <- 21
  item_id[newstype == "Real1_7"] <- 22
  item_id[newstype == "Real1_8"] <- 23
  item_id[newstype == "Real1_9"] <- 24
  item_id[newstype == "Real1_10"] <- 25
  item_id[newstype == "Real1_11"] <- 26
  item_id[newstype == "Real1_12"] <- 27
  item_id[newstype == "Real1_13"] <- 28
  item_id[newstype == "Real1_14"] <- 29
  item_id[newstype == "Real1_15"] <- 30
})

library(lme4) 
library(lmerTest)

#model 1, item_id indicates repeated measurements for each item
mult1 <- lmer (measurement ~ condition + attentioncheck + headlineveracity + (1|item_id),
             data = pennys2r1long)
summary(mult1)

```



### reproduction of figure 2 without considering attention check

### graph 1: including all
```{r, message=FALSE}

library(ggplot2)

#Since the plot not specify which condition they use, then I need to plot all 4 graph in different condition

#condition 1: all

#Find out the sum for each type of news in different condition

p1 <- aggregate(measurement~condition+headlineveracity, data = pennys2r1long_nona, na.rm = TRUE, FUN = sum)


#since the obs is 25,627, thus for each news in each condition, it observed 25,627/4 = 6406.75
p1 <- transform(p1, percent = ave(measurement, condition, FUN = function(x) paste0(round(x/6406.75, 4)*100)))

#plot the graph

ggplot(p1, aes(x = condition, y = as.numeric(percent), fill = headlineveracity)) + 
  geom_bar(stat = 'identity',position = 'dodge') + 
  geom_text(
    aes(label = as.numeric (percent)), vjust = 1.5, position = position_dodge(0.9))
```
### graph 2 attention check above and equal to 1

```{r, message=FALSE}

#condition 2: above and equal to 1

pennystudy2plot2 <- pennys2r1longa1 %>%
  select (c(1, 2, 3, 4))

#separating the sheet

pennystudy2plot2c <- subset(pennystudy2plot2, condition %in% c("0"))
pennystudy2plot2t <- subset(pennystudy2plot2, condition %in% c("1"))


#Find out the sum for each type of news in different condition
p2 <- aggregate(measurement~condition+newstype, data = pennystudy2plot2, FUN = sum)

##double check for correctness
sum(pennystudy2plot2$measurement,na.rm = TRUE)

#since the obs is 1664, thus 1664/2 = 832 participants. So to get percentage of sharing intention each fake and real news need to divided by 832/2 = 416
ggplot(p2, aes(x = condition, y = measurement/428, fill = newstype)) + 
  geom_bar(stat = 'identity',position = 'dodge') + 
  geom_text(
    aes(label = round(measurement/428, digits = 3)), vjust = 1.5, position = position_dodge(0.9))+
    scale_y_continuous(labels = scales::percent)
```

### graph 3 attention check above and equal to 2
```{r, message=FALSE}
#condition 3: above and equal to 2
pennystudy2plot3 <- pennys2r1longa2 %>%
  select (c(1, 2, 3, 4))


#Find out the sum for each type of news in different condition

p3 <- aggregate(measurement~condition+newstype, data = pennystudy2plot3, na.rm = TRUE, FUN = sum)
p3 <- transform(p3, percent = ave(measurement, condition, FUN = function(x) paste0(round(x/428, 4)*100)))


##double check for correctness
sum(pennystudy2plot3$measurement,na.rm = TRUE)

#plot the graph under the proportion of overall observation (856)
ggplot(p3, aes(x = condition, y = as.numeric(percent), fill = newstype)) + 
  geom_bar(stat = 'identity',position = 'dodge') + 
  geom_text(
    aes(label = as.numeric (percent)), vjust = 1.5, position = position_dodge(0.9))
```
### graph 3 attention check above and equal to 2: mean
```{r, message=FALSE}
#condition 3: above and equal to 2
pennystudy2plot3 <- pennys2r1longa2 %>%
  select (c(1, 2, 3, 4))

pennystudy2plot3c <- subset(pennystudy2plot3, condition %in% c("0"))
pennystudy2plot3t <- subset(pennystudy2plot3, condition %in% c("1"))


#Find out the sum and percentage for each type of news in each condition

##control, percentage = 658/2 = 329
p31 <- aggregate(measurement~condition+newstype, data = pennystudy2plot3c, na.rm = TRUE, FUN = sum)
p31 <- transform(p31, percent = ave(measurement, condition, FUN = function(x) paste0(round(x/329, 4)*100)))

##treatment, percentage = 634/2 = 317
p32 <- aggregate(measurement~condition+newstype, data = pennystudy2plot3t, na.rm = TRUE, FUN = sum)
p32 <- transform(p32, percent = ave(measurement, condition, FUN = function(x) paste0(round(x/317, 4)*100)))

#merge two table together under same column name
p3 <- rbind(p31,p32)

##double check for correctness
sum(pennystudy2plot3$measurement,na.rm = TRUE)

#plot the graph
ggplot(p3, aes(x = condition, y = as.numeric(percent), fill = newstype)) + 
  geom_bar(stat = 'identity',position = 'dodge') + 
  geom_text(
    aes(label = as.numeric (percent)), vjust = 1.5, position = position_dodge(0.9))
```









### graph 4 attention check equal to 3
```{r, message=FALSE}
#condition 3: equal to 3
pennystudy2plot4 <- pennys2r1longa3 %>%
  select (c(1, 2, 3, 4))

#Find out the sum for each type of news in different condition
p4 <- aggregate(measurement~condition+newstype, data = pennystudy2plot4, FUN = sum)

##double check
sum(pennystudy2plot4$measurement,na.rm = TRUE)

#since the obs is 460 for attention = 3, thus 460/2 = 230 participants. So to get percentage of sharing intention each fake and real news need to divided by 230/2 = 115
ggplot(p4, aes(x = condition, y = measurement/115, fill = newstype)) + 
  geom_bar(stat = 'identity',position = 'dodge') + 
  geom_text(
    aes(label = round(measurement/115, digits = 3)), vjust = 1.5, position = position_dodge(0.9))+
    scale_y_continuous(labels = scales::percent)
```


















